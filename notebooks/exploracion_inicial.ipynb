{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0fcc35",
   "metadata": {},
   "source": [
    "# EV1 Minería de Datos (BIY7121_001V)\n",
    "\n",
    "### **Profesor:** *Giocrisrai Godoy Bonillo*\n",
    "\n",
    "### **Alumnos:**\n",
    "   ### *- Abraham Rubilar*\n",
    "   ### *- Francisco Castro*\n",
    "   ### *- Hernán Garrido*\n",
    "   ### *- Tyhara Mujica*\n",
    "\n",
    "_________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb457d-6b2e-4ce9-ac1f-30d8f1435c3c",
   "metadata": {},
   "source": [
    "# Fase 1 Business Understanding\n",
    "\n",
    "El proyecto se enfoca en mejorar el pronóstico meteorológico en Australia, utilizando la metodología CRISP-DM para abordar de manera integral tanto los objetivos de negocio como los de minería de datos.\n",
    "\n",
    "### Objetivos de Negocio:\n",
    "\n",
    "Mejorar la capacidad predictiva: Se busca anticipar con precisión la ocurrencia de lluvia al día siguiente (RainTomorrow) y cuantificar la cantidad de lluvia utilizando variables continuas (RISK_MM y Rainfall). Esta capacidad es esencial para sectores críticos como la agricultura, la gestión de emergencias y la planificación urbana.\n",
    "\n",
    "Cuantificar y gestionar el riesgo: La variable RISK_MM se utiliza para medir el nivel de riesgo ante eventos meteorológicos extremos, mientras que Rainfall permite analizar patrones y tendencias estacionales, lo que ayuda a implementar estrategias de mitigación frente a inundaciones o incendios forestales.\n",
    "\n",
    "Optimizar la toma de decisiones: Con pronósticos precisos y un análisis detallado del riesgo, se pretende apoyar la asignación eficiente de recursos y la planificación estratégica en contextos críticos, beneficiando tanto a instituciones públicas como a entidades privadas.\n",
    "\n",
    "Soportar la planificación estratégica: Una mejor predicción del clima impacta sectores clave como la minería, el turismo y la infraestructura, permitiendo desarrollar políticas preventivas y estrategias de negocio adaptadas a la diversidad climática de Australia.\n",
    "\n",
    "### Objetivos de Minería de Datos:\n",
    "\n",
    "Exploración y limpieza del dataset: Garantizar la calidad de los datos mediante la detección y corrección de valores faltantes y atípicos en variables tanto continuas (temperaturas, humedad, precipitación) como categóricas (dirección del viento, indicadores binarios).\n",
    "\n",
    "Identificación de patrones y selección de variables relevantes: Determinar cuáles variables tienen un impacto significativo en la ocurrencia de lluvia y en la cuantificación del riesgo, aprovechando el potencial predictivo de RISK_MM y Rainfall para captar tendencias y estacionalidades.\n",
    "\n",
    "Desarrollo y validación de modelos predictivos: Implementar modelos de clasificación para predecir RainTomorrow y modelos de regresión para estimar RISK_MM, complementados por análisis de series de tiempo para capturar patrones temporales.\n",
    "\n",
    "Interpretabilidad y acción sobre los resultados: Asegurar que los resultados sean comprensibles y útiles para los tomadores de decisiones, facilitando la transformación de los hallazgos en acciones operativas y estratégicas.\n",
    "\n",
    "### Criterios de Éxito:\n",
    "\n",
    "Precisión y robustez: Los modelos deben lograr altas tasas de acierto, minimizando errores tanto en la clasificación como en la estimación de la cantidad de lluvia.\n",
    "\n",
    "Valor práctico: Las predicciones deben traducirse en mejoras en la gestión de recursos y en la mitigación de riesgos en sectores críticos.\n",
    "\n",
    "Escalabilidad y actualización: La solución debe ser flexible para incorporar nuevos datos y adaptarse a cambios en las condiciones meteorológicas, garantizando su efectividad a lo largo del tiempo.\n",
    "\n",
    "### Identificación de KPI's relevantes:\n",
    "\n",
    "A continuación, se presentan tres KPI's relevantes, alineados con los objetivos identificados para modelos de clasificación, regresión y predicción con series de tiempo:\n",
    "\n",
    "1.\tPrecisión en la Clasificación (RainTomorrow): \n",
    "Mide el porcentaje de aciertos en la predicción de si lloverá o no al día siguiente, utilizando métricas como la exactitud, precisión, recall o F1-score. Este KPI es fundamental para evaluar la capacidad del modelo de clasificación de anticipar correctamente los eventos de lluvia.\n",
    "\n",
    "2.\tError en la Predicción de Regresión (RISK_MM):\n",
    "Evalúa la precisión del modelo de regresión en la estimación de la cantidad de lluvia (medida en milímetros) utilizando métricas como el Error Medio Absoluto (MAE) o el Error Cuadrático Medio (RMSE). Un menor valor indica mayor precisión en la cuantificación del riesgo.\n",
    "\n",
    "3.\tPrecisión en la Predicción con Series de Tiempo (Rainfall):  \n",
    "Mide la capacidad del modelo de series de tiempo para captar patrones estacionales y tendencias en la cantidad diaria de lluvia. Se puede evaluar mediante el Error Porcentual Absoluto Medio (MAPE) o el RMSE aplicado a las predicciones temporales, lo cual es clave para anticipar variaciones a lo largo del tiempo.\n",
    "\n",
    "### Preguntas preliminares:\n",
    "\n",
    "1. Para el Modelo de Clasificación (RainTomorrow)\n",
    "- ¿Cómo se distribuyen las clases de la variable RainTomorrow en el dataset?\n",
    "\n",
    "- ¿Existe un desequilibrio en la proporción de días con y sin lluvia que pueda afectar la clasificación?\n",
    "\n",
    "- ¿Qué nivel de datos faltantes o inconsistencias se encuentran en las variables relacionadas con el pronóstico (por ejemplo, temperaturas, humedad, presión) que influyen en RainTomorrow?\n",
    "\n",
    "2. Para el Modelo de Regresión (RISK_MM)\n",
    "- ¿Cuál es la distribución de la variable RISK_MM y se identifican outliers que puedan distorsionar el análisis?\n",
    "\n",
    "- ¿Qué correlación existe entre RISK_MM y otras variables meteorológicas como temperatura, humedad y presión?\n",
    "\n",
    "- ¿Es necesaria alguna transformación o normalización en RISK_MM para mejorar la capacidad predictiva de los modelos de regresión?\n",
    "\n",
    "3. Para la Predicción con Series de Tiempo (Rainfall)\n",
    "- ¿Qué patrones estacionales, tendencias y ciclos se observan en la variable Rainfall a lo largo del tiempo?\n",
    "\n",
    "- ¿Existen anomalías o eventos extremos en la serie temporal de Rainfall que requieran un tratamiento especial?\n",
    "\n",
    "- ¿Cómo varían las mediciones de Rainfall en función de las diferentes ubicaciones geográficas y épocas del año?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08577804-3607-4646-a055-990948e0b9d0",
   "metadata": {},
   "source": [
    "### Descripción inicial del Dataset:\n",
    "\n",
    "| COLUMNA       | Tipo    | Descripción |\n",
    "|---------------|---------|-------------|\n",
    "| Date          | object  | Fecha de observación |\n",
    "| Location      | object  | Ubicación de la estación meteorológica |\n",
    "| MinTemp       | float64 | Temperatura máxima en grados Celsius |\n",
    "| MaxTemp       | float64 | Temperatura mínima en grados Celsius |\n",
    "| Rainfall      | float64 | Cantidad de lluvia registrada ese día en mm. |\n",
    "| Evaporation   | float64 | Evaporación (mm) en 24 horas |\n",
    "| Sunshine      | float64 | Número de horas de sol brillante en el día |\n",
    "| WindGustDir   | object  | Dirección de la ráfaga de viento más fuerte en 24 horas |\n",
    "| WindGustSpeed | float64 | Velocidad (km/hr) de la ráfaga de viento más fuerte en 24 horas |\n",
    "| WindDir9am    | object  | Dirección del viento a las 9am |\n",
    "| WindDir3pm    | object  | Dirección del viento a las 3pm |\n",
    "| WindSpeed9am  | float64 | Velocidad (km/hr) del viento a las 9am |\n",
    "| WindSpeed3pm  | float64 | Velocidad (km/hr) del viento a las 3pm |\n",
    "| Humidity9am   | float64 | Porcentaje de humedad a las 9am |\n",
    "| Humidity3pm   | float64 | Porcentaje de humedad a las 3pm |\n",
    "| Pressure9am   | float64 | Presión atmosférica (hpa) a nivel del mar a las 9am |\n",
    "| Pressure3pm   | float64 | Presión atmosférica (hpa) a nivel del mar a las 3pm |\n",
    "| Cloud9am      | float64 | Fracción del cielo cubierto por nubes a las 9am. Se mide en \"octavos\": 0 indica cielo totalmente despejado y 8, cielo totalmente cubierto. |\n",
    "| Cloud3pm      | float64 | Fracción del cielo cubierto por nubes a las 3pm. Se mide en \"octavos\": 0 indica cielo totalmente despejado y 8, cielo totalmente cubierto. |\n",
    "| Temp9am       | float64 | Temperatura en grados Celsius a las 9am |\n",
    "| Temp3pm       | float64 | Temperatura en grados Celsius a las 3pm |\n",
    "| RainToday     | object  | Variable indicadora: 1 si la precipitación en mm en las últimas 24 hrs excede 1 mm, y 0 si no. |\n",
    "| RISK_MM       | float64 | La cantidad de lluvia. Una especie de medida del \"riesgo\". |\n",
    "| RainTomorrow  | object  | Variable indicadora: 1 si al día siguiente llovió, y 0 si no. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7f287",
   "metadata": {},
   "source": [
    "# Fase 2 Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7771f0c-1ff4-4356-94fb-92da1c536e34",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5ade82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.12\n"
     ]
    }
   ],
   "source": [
    "import kedro\n",
    "print(kedro.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Configuración para que los gráficos se muestren en el Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb144e4-d6a2-4ad6-9804-1982c88af773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1284595-0966-49f1-b79e-e1761085a469",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "Utilizando la variable global ('catalog') de Kedro, donde se almacena la información de los dataset como un catálogo de datos. Se procede a crear un dataframe, para obtener una primera impresión de sus registros y columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = catalog.load(\"csv_weather_aus\") # \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e212b4",
   "metadata": {},
   "source": [
    "### Revisamos las dimensiones del dataset en cuestión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c479dd-3e86-4bd0-a3c5-ed61ed0b9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensiones del Dataset: Tiene {df.shape[0]} filas, y {df.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07ceef-fff6-4f7f-b32e-322564fa1ae1",
   "metadata": {},
   "source": [
    "### Revisamos las 10 últimas filas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef415f-c65a-45f9-8419-9e6a3a7e763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f39892-2a86-485c-a18f-1220f609a42e",
   "metadata": {},
   "source": [
    "### Información y Tipos de Datos\n",
    "Con el método .info() podemos ver la estructura del DataFrame, identificar el tipo de cada variable y detectar posibles valores nulos. Esto es esencial para determinar qué variables requieren limpieza o transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd45b48-311a-47a3-bb4f-5b9fb5cee4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset\n",
    "print(\"Información del dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc19037-499d-4bb5-8d0b-e67aeb8707a8",
   "metadata": {},
   "source": [
    "### Análisis de Valores Nulos y Duplicados\n",
    "Identificar la cantidad y distribución de valores faltantes es crucial para planificar las estrategias de limpieza. Además, revisaremos la presencia de registros duplicados que podrían sesgar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e96e24-78ab-4c22-9192-77c4b6eda031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la cantidad de valores nulos en cada columna\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nValores nulos por columna:\\n\")\n",
    "print(missing_values)\n",
    "\n",
    "# Revisar si existen registros duplicados\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"\\nCantidad de registros duplicados:\", duplicates, \"registros.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83968957-48fa-48c6-b912-a1189bc077a8",
   "metadata": {},
   "source": [
    "### Conversión de Tipos de Datos\n",
    "Recomendaciones basadas en el caso de estudio:\n",
    "\n",
    "Fecha: Convertir la columna Date de string a datetime para extraer información temporal (año, mes, día de la semana).\n",
    "\n",
    "Variables Categóricas: Convertir columnas como Location, RainToday, RainTomorrow y las de direcciones del viento (WindGustDir, WindDir9am, WindDir3pm) a tipo category para optimizar la memoria y facilitar el análisis.\n",
    "\n",
    "Variables Numéricas: Verificar que las columnas numéricas se encuentren en el formato adecuado y, en caso contrario, convertirlas utilizando pd.to_numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ed6e2-543b-4430-9122-547f3227fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Date' a datetime\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Convertir variables categóricas\n",
    "categorical_cols = ['Location', 'RainToday', 'RainTomorrow', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Conversión para columnas numéricas (verifica según tu dataset)\n",
    "numeric_cols = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed',\n",
    "                'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', \n",
    "                'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'RISK_MM']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Verificar nuevamente la información del dataset después de las conversiones\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f1b02-01cd-41f5-9456-a6f31e2acbbd",
   "metadata": {},
   "source": [
    "### Estadísticas Descriptivas\n",
    "Se obtienen estadísticas descriptivas para las variables numéricas y categóricas. Esto permite conocer la distribución, la media, la desviación estándar y otros percentiles que pueden ser útiles para detectar posibles outliers o comportamientos anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d515f4f-7f6b-4f5e-ae87-4a86aa15e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas de variables numéricas\n",
    "display(df.describe())\n",
    "\n",
    "# Estadísticas para variables categóricas (si es necesario)\n",
    "display(df.describe(include=['category']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f3bec-0660-497b-84a2-058e4df02f3f",
   "metadata": {},
   "source": [
    "### Análisis de Valores Faltantes\n",
    "Es fundamental identificar la proporción y el patrón de los valores faltantes. Esto nos ayudará a decidir estrategias de imputación o eliminación.\n",
    "\n",
    "Se utilizará un heatmap para visualizar la presencia de valores faltantes y, opcionalmente, la librería 'missingno' para un análisis interactivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40af1d2-dc1b-4003-a259-849fd8aa0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el porcentaje de valores nulos por columna\n",
    "missing_pct = df.isnull().mean() * 100\n",
    "missing_df = pd.DataFrame({'Porcentaje de valores nulos': missing_pct}).sort_values(by='Porcentaje de valores nulos', ascending=False)\n",
    "print(\"Porcentaje de valores faltantes por columna:\")\n",
    "display(missing_df)\n",
    "\n",
    "# Visualizar valores faltantes mediante un heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Mapa de valores faltantes\")\n",
    "plt.show()\n",
    "\n",
    "# Opcional: Visualización interactiva con missingno\n",
    "try:\n",
    "    msno.matrix(df, figsize=(12, 6))\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"La librería missingno no está instalada. Puedes instalarla con '!pip install missingno'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c9776-3ee0-451b-8165-834f040b198a",
   "metadata": {},
   "source": [
    "### Análisis de Variables Numéricas: Distribuciones y Detección de Outliers\n",
    "\n",
    "Visualizaremos histogramas y boxplots de las variables numéricas para comprender su distribución y detectar la presencia de outliers, lo cual es fundamental para definir estrategias de transformación o limpieza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fede8b-579d-4057-9c9d-c4df23a44e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas numéricas\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Histogramas\n",
    "plt.figure(figsize=(18, 16))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(5, 4, i)\n",
    "    sns.histplot(df[col].dropna(), kde=True, bins=30)\n",
    "    plt.title(f'Histograma de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para detectar outliers\n",
    "plt.figure(figsize=(18, 16))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(5, 4, i)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1e254-2436-4070-a9c5-7566236e1edb",
   "metadata": {},
   "source": [
    "### Análisis de Variables Categóricas\n",
    "\n",
    "Se examinan las distribuciones de las variables categóricas mediante gráficos de barras.  \n",
    "Esto es especialmente relevante para detectar posibles desequilibrios en la variable objetivo (*RainTomorrow*) y en otras variables cualitativas como la dirección del viento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa598d-6845-4e8b-807e-f150144b3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas categóricas\n",
    "categorical_cols = df.select_dtypes(include=['category']).columns\n",
    "\n",
    "plt.figure(figsize=(18, 20))\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(6, 2, i)\n",
    "    df[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f'Frecuencia de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Conteo')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b25d12-a22f-43d2-9874-386dd62b8e24",
   "metadata": {},
   "source": [
    "### Análisis de la Variable Objetivo y KPI's Relacionados\n",
    "\n",
    "- **RainTomorrow:**  \n",
    "  Analizaremos la distribución de la variable que indica si lloverá al día siguiente para identificar posibles problemas de desequilibrio de clases.\n",
    "\n",
    "- **RISK_MM y Rainfall:**  \n",
    "  Se estudiarán las distribuciones de estas variables para detectar outliers y evaluar la necesidad de transformaciones, dado que son clave para cuantificar el riesgo y la cantidad de lluvia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b74ff-7161-4a17-b02a-dcfb765e6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de RainTomorrow\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='RainTomorrow', data=df)\n",
    "plt.title('Distribución de RainTomorrow')\n",
    "plt.xlabel('RainTomorrow (0 = No, 1 = Sí)')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n",
    "\n",
    "# Histogramas de RISK_MM y Rainfall\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['RISK_MM'].dropna(), kde=True, bins=30)\n",
    "plt.title('Distribución de RISK_MM')\n",
    "plt.xlabel('RISK_MM')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['Rainfall'].dropna(), kde=True, bins=30)\n",
    "plt.title('Distribución de Rainfall')\n",
    "plt.xlabel('Rainfall (mm)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b36f7-f804-4133-be42-b1ad52366d0f",
   "metadata": {},
   "source": [
    "### Análisis de Correlaciones y Relaciones entre Variables\n",
    "\n",
    "El análisis de la matriz de correlación ayuda a identificar relaciones significativas entre variables numéricas.  \n",
    "Se examinarán correlaciones relevantes, como entre las temperaturas, la humedad, la presión y las variables de precipitación (*Rainfall* y *RISK_MM*), para fundamentar la selección de variables en modelos predictivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7a375-f756-42f3-b82d-8cb88fc5ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(14,12))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Mapa de Calor de Correlaciones')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot de variables seleccionadas (por ejemplo, variables de temperatura, humedad y lluvia)\n",
    "selected_vars = ['MinTemp', 'MaxTemp', 'Rainfall', 'RISK_MM', 'Humidity9am', 'Humidity3pm']\n",
    "sns.pairplot(df[selected_vars].dropna())\n",
    "plt.suptitle('Pairplot de Variables Seleccionadas', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e6346",
   "metadata": {},
   "source": [
    "### Tratamiento de Outliers con IQR\n",
    "\n",
    "Se aplicó la técnica IQR para eliminar valores atípicos en variables numéricas continuas como `Rainfall`, `RISK_MM`, `Evaporation`, `WindGustSpeed`, entre otras.\n",
    "\n",
    "Esta técnica identifica outliers como aquellos valores que se encuentran fuera del rango:\n",
    "\\[\n",
    "[Q1 - 1.5 \\times IQR,\\ Q3 + 1.5 \\times IQR]\n",
    "\\]\n",
    "\n",
    "La eliminación de estos valores extremos mejora la robustez de modelos de regresión y clasificación, y evita que predicciones se vean distorsionadas por anomalías no representativas del comportamiento general del clima.\n",
    "\n",
    "Después del filtrado, se conserva la mayoría del dataset sin los valores extremos que afectan la distribución. A continuación, generamos las visualizaciones que dan cuenta de ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c63f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del dataset original para comparar antes y después\n",
    "df_original = df.copy()\n",
    "\n",
    "# Variables numéricas a filtrar con IQR\n",
    "numeric_cols = ['Rainfall', 'RISK_MM', 'Evaporation', 'WindGustSpeed', \n",
    "                'WindSpeed9am', 'WindSpeed3pm', 'Sunshine', \n",
    "                'MinTemp', 'MaxTemp', 'Humidity9am', 'Humidity3pm',\n",
    "                'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "\n",
    "# Aplicar IQR\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "# Generar comparación visual antes y después para algunas variables clave\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(14, 20))\n",
    "variables_to_plot = ['Rainfall', 'RISK_MM', 'Evaporation', 'WindGustSpeed', 'Humidity3pm']\n",
    "\n",
    "for i, var in enumerate(variables_to_plot):\n",
    "    sns.boxplot(data=df_original, x=var, ax=axes[i, 0], color='salmon')\n",
    "    axes[i, 0].set_title(f'{var} (Antes del IQR)')\n",
    "    sns.boxplot(data=df, x=var, ax=axes[i, 1], color='lightblue')\n",
    "    axes[i, 1].set_title(f'{var} (Después del IQR)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos algunas variables relevantes para graficar\n",
    "\n",
    "# A. Gráficos de barras para variables categóricas\n",
    "categorical_summary = df_original['RainTomorrow'].value_counts()\n",
    "\n",
    "# B. Gráficos de dispersión (scatter) para variables numéricas vs RISK_MM\n",
    "scatter_variables = ['Rainfall', 'Humidity3pm', 'Evaporation', 'WindGustSpeed', 'Cloud3pm']\n",
    "\n",
    "# Crear subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))\n",
    "\n",
    "# A. Barra - Distribución de RainTomorrow\n",
    "axs[0, 0].bar(categorical_summary.index, categorical_summary.values, color=['skyblue', 'salmon'])\n",
    "axs[0, 0].set_title(\"Distribución de RainTomorrow\")\n",
    "axs[0, 0].set_xlabel(\"RainTomorrow\")\n",
    "axs[0, 0].set_ylabel(\"Cantidad\")\n",
    "\n",
    "# B. Dispersión: Cada variable vs RISK_MM\n",
    "for i, var in enumerate(scatter_variables):\n",
    "    row, col = divmod(i+1, 3)\n",
    "    axs[row, col].scatter(df[var], df['RISK_MM'], alpha=0.3, s=10)\n",
    "    axs[row, col].set_title(f\"{var} vs RISK_MM\")\n",
    "    axs[row, col].set_xlabel(var)\n",
    "    axs[row, col].set_ylabel(\"RISK_MM\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7613ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear histogramas para todas las variables numéricas después del filtrado IQR\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Definir tamaño de figura y número de subplots por figura\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(numeric_columns) / n_cols))\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(18, n_rows * 4))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Graficar histogramas\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.histplot(df[col].dropna(), bins=30, kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Histograma de {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "\n",
    "# Ocultar subplots vacíos si hay\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación para las variables numéricas\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Crear un heatmap de correlaciones\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5, square=True)\n",
    "plt.title('Mapa de Calor de Correlaciones entre Variables Numéricas')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d34313-1229-4171-aef5-e55ac022770d",
   "metadata": {},
   "source": [
    "### Análisis Temporal y Estacionalidad\n",
    "\n",
    "La variable `Date` permite analizar la evolución de las condiciones meteorológicas a lo largo del tiempo.  \n",
    "Se convertirán y extraerán componentes temporales (año, mes, día) para visualizar:\n",
    "- Tendencias generales en *Rainfall*.\n",
    "- Patrones estacionales y mensuales.\n",
    "- Comportamiento de las variables en función de la ubicación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fc8f1-5a58-4181-93ec-9335442e3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de la columna 'Date' a formato datetime y extracción de componentes\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "\n",
    "# Visualización de Rainfall a lo largo del tiempo\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df['Date'], df['Rainfall'], alpha=0.5, label='Rainfall')\n",
    "plt.title('Evolución de Rainfall a lo largo del tiempo')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Rainfall (mm)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Agregación mensual de Rainfall\n",
    "monthly_rainfall = df.groupby(['Year', 'Month'])['Rainfall'].mean().reset_index()\n",
    "monthly_rainfall['Date'] = pd.to_datetime(monthly_rainfall[['Year', 'Month']].assign(DAY=1))\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(monthly_rainfall['Date'], monthly_rainfall['Rainfall'], marker='o')\n",
    "plt.title('Promedio mensual de Rainfall')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Rainfall Promedio (mm)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1adc5-bc99-4463-a3bd-625f5e2a3bfc",
   "metadata": {},
   "source": [
    "### Análisis por Ubicación\n",
    "\n",
    "Dado que Australia presenta una diversidad climática notable según la ubicación, se realizará un análisis agrupado por la variable *Location*.  \n",
    "Se explorará la variación de variables clave (temperaturas, precipitación, etc.) en las principales ubicaciones, lo que facilitará identificar patrones locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706494d5-c285-4e11-8a5d-98a7d875280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas resumidas de Rainfall por Location\n",
    "location_summary = df.groupby('Location')['Rainfall'].agg(['mean', 'median', 'std', 'min', 'max']).reset_index()\n",
    "location_summary.sort_values(by='mean', ascending=False, inplace=True)\n",
    "print(location_summary)\n",
    "\n",
    "# Visualización: Promedio de Rainfall por Location (top 10)\n",
    "top10_locations = location_summary.head(10)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='mean', y='Location', data=top10_locations, palette='viridis')\n",
    "plt.title('Top 10 Locations con Mayor Promedio de Rainfall')\n",
    "plt.xlabel('Rainfall Promedio (mm)')\n",
    "plt.ylabel('Location')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bfe5d-3d57-4426-b6d4-f80b67a5517e",
   "metadata": {},
   "source": [
    "### Detección de Outliers y Consideraciones para Transformaciones\n",
    "\n",
    "A partir de los boxplots y histogramas se han detectado outliers en algunas variables (especialmente en *RISK_MM* y *Rainfall*).  \n",
    "En fases posteriores (Data Preparation), se evaluará si es necesario aplicar transformaciones (por ejemplo, transformación logarítmica) o técnicas de winsorización para mitigar el efecto de valores extremos.\n",
    "\n",
    "### Conclusiones del Análisis Exploratorio (EDA)\n",
    "\n",
    "- **Calidad de los Datos:**  \n",
    "  Se identificaron variables con valores faltantes que deberán ser tratadas. La estructura general del dataset es adecuada, pero se detectan algunos outliers en variables críticas.\n",
    "\n",
    "- **Distribución y Outliers:**  \n",
    "  Las variables numéricas presentan distribuciones diversas; en particular, *RISK_MM* y *Rainfall* muestran presencia de valores extremos que podrían requerir transformaciones.\n",
    "\n",
    "- **Variables Categóricas:**  \n",
    "  Se observa un posible desequilibrio en la variable objetivo *RainTomorrow*, lo que es importante considerar en el modelado de clasificación.\n",
    "\n",
    "- **Relaciones y Correlaciones:**  \n",
    "  El análisis de correlaciones y el pairplot revelan relaciones significativas entre variables meteorológicas (temperaturas, humedad, presión) y las variables de precipitación, lo que ayudará en la selección de características para futuros modelos.\n",
    "\n",
    "- **Análisis Temporal y por Ubicación:**  \n",
    "  Se han identificado tendencias y patrones estacionales en *Rainfall*, así como variaciones notables según la ubicación, lo cual es esencial para capturar la diversidad climática de Australia.\n",
    "\n",
    "Estos hallazgos proporcionan una base sólida para proceder a la fase de Data Preparation y, posteriormente, a la modelación predictiva, orientada a mejorar la capacidad de pronóstico y gestión del riesgo.\n",
    "\n",
    "Con este análisis exploratorio robusto se han abordado en profundidad los aspectos críticos del dataset, sentando las bases para la fase de Data Preparation.  \n",
    "En esta siguiente fase se procederá a la limpieza, transformación y preparación de los datos para la construcción de modelos predictivos que cumplan con los objetivos de negocio planteados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87259af",
   "metadata": {},
   "source": [
    "# Fase 3 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeda1a5",
   "metadata": {},
   "source": [
    "### A partir de este punto, vamos a proceder a utilizar el dataframe original, anterior a la implementación de IQR. Luego, lo limpiaremos y haremos las transformaciones necesarias, con el fin de poder alimentar con datos de calidad a los futuros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740367c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tomamos el dataset original para proceder con los procesos de limpieza y transformación.\n",
    "df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c24d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversiones temporales.\n",
    "df_original['Year'] = df_original['Date'].dt.year\n",
    "df_original['Month'] = df_original['Date'].dt.month\n",
    "df_original['Day'] = df_original['Date'].dt.day\n",
    "df_original['DayOfWeek'] = df_original['Date'].dt.dayofweek\n",
    "df_original['Quarter'] = df_original['Date'].dt.quarter\n",
    "df_original['WeekOfYear'] = df_original['Date'].dt.isocalendar().week\n",
    "df_original['IsWeekend'] = df_original['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0) \n",
    "\n",
    "# Mapeo de estaciones según el mes.\n",
    "seasons = {\n",
    "    2: 'Summer',  # Febrero\n",
    "    1: 'Summer',  # Enero\n",
    "    3: 'Autumm',   # Marzo\n",
    "    4: 'Autumm',   # Abril\n",
    "    5: 'Autumm',   # Mayo\n",
    "    6: 'Winter', # Junio\n",
    "    7: 'Winter', # Julio\n",
    "    8: 'Winter', # Agosto\n",
    "    9: 'Spring',# Septiembre\n",
    "    10: 'Spring',# Octubre\n",
    "    11: 'Spring',# Noviembre\n",
    "    12: 'Summer'   # Diciembre\n",
    "}\n",
    "df_original['Season'] = df_original['Month'].map(seasons)\n",
    "df_original['Season'] = df_original['Season'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05934a",
   "metadata": {},
   "source": [
    "Imputación de valores faltantes aplicando estrategias diferenciadas (según variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Primero tratar variables con menos nulos\n",
    "# Temperatura y humedad (bajo % de nulos)\n",
    "# Variables numéricas con bajo % de nulos\n",
    "low_null_cols = ['Temp9am', 'Temp3pm', 'Humidity9am', 'Humidity3pm', \n",
    "                'WindSpeed9am', 'WindSpeed3pm', 'MinTemp', 'MaxTemp']\n",
    "\n",
    "# Imputador KNN para variables numéricas básicas\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_original[low_null_cols] = imputer.fit_transform(df_original[low_null_cols])\n",
    "\n",
    "# 2. Rainfall y RainToday (imputación cruzada)\n",
    "# Si RainToday es conocido pero Rainfall no\n",
    "df_original.loc[df_original['RainToday'].notna() & df_original['Rainfall'].isna(), 'Rainfall'] = df_original.loc[df_original['RainToday'] == 'Yes', 'Rainfall'].apply(\n",
    "        lambda x: np.random.uniform(0.2, 2.0) if pd.isna(x) else x)\n",
    "    \n",
    "# Si Rainfall es conocido pero RainToday no\n",
    "df_original.loc[df_original['Rainfall'].notna() & df_original['RainToday'].isna(), 'RainToday'] = df_original['Rainfall'].apply(lambda x: 'Yes' if x > 0.0 else 'No')\n",
    "\n",
    "# 3. Pressure (imputación por grupo)\n",
    "for col in ['Pressure9am', 'Pressure3pm']:\n",
    "    df_original[col] = df_original.groupby(['Location', df_original['Month']], observed=False)[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "# 4. Cloud9am y Cloud3pm\n",
    "for col in ['Cloud9am', 'Cloud3pm']:\n",
    "    # Calcular la mediana una sola vez por grupo y usarla para imputación\n",
    "    df_original[col] = df_original.groupby(['Location', 'Season'], observed=False)[col].transform(lambda x: x.fillna(x.median() if not pd.isna(x.median()) else 0))\n",
    "\n",
    "# 5. Para Sunshine (alto % de nulos)\n",
    "for col in ['Sunshine', 'Evaporation']:\n",
    "    # Calcular la mediana una sola vez por grupo y usarla para imputación\n",
    "    df_original[col] = df_original.groupby(['Location', 'Season'], observed=False)[col].transform(lambda x: x.fillna(x.median() if not pd.isna(x.median()) else 0))\n",
    "    \n",
    "\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si quedan valores nulos\n",
    "missing_values = df_original.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nValores nulos por columna después de la imputación diferenciada:\\n\")\n",
    "print(missing_values[missing_values > 0]) # Solo muestra columnas con nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d9642",
   "metadata": {},
   "source": [
    "Aplicando IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función que remueva outliers utilizando el método IQR\n",
    "def remove_outliers_iqr(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return series[(series >= lower_bound) & (series <= upper_bound)]\n",
    "\n",
    "# Revisamos cuales son las variables que tienen outliers\n",
    "outlier_columns = df_original.select_dtypes(include=['float64', 'int64']).columns\n",
    "outlier_columns = outlier_columns[~df_original[outlier_columns].isnull().all()]\n",
    "\n",
    "print(\"Variables con outliers:\\n\")\n",
    "print(outlier_columns)\n",
    "\n",
    "# Graficamos boxplots para las variables que tienen outliers\n",
    "plt.figure(figsize=(18, 16))\n",
    "for i, col in enumerate(outlier_columns, 1):\n",
    "    plt.subplot(5, 4, i)\n",
    "    sns.boxplot(x=df_original[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6baebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En base al gráfico anterior, decidimos eliminar los outliers de las siguientes variables:\n",
    "cols_iqr = ['Evaporation', 'WindGustSpeed', \n",
    "                'WindSpeed9am', 'WindSpeed3pm', 'Sunshine', \n",
    "                'MinTemp', 'MaxTemp','Pressure9am', 'Pressure3pm', \n",
    "                'Temp9am', 'Temp3pm'\n",
    "]\n",
    "\n",
    "# Aplicamos la función de eliminación de outliers a las columnas seleccionadas\n",
    "for col in cols_iqr:\n",
    "    df_original[col] = remove_outliers_iqr(df_original[col])\n",
    "\n",
    "df_original\n",
    "\n",
    "# Graficamos \n",
    "plt.figure(figsize=(18, 16))\n",
    "for i, col in enumerate(outlier_columns, 1):\n",
    "    plt.subplot(5, 4, i)\n",
    "    sns.boxplot(x=df_original[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451dd49",
   "metadata": {},
   "source": [
    "Tratamiento e inclusión de RISK_MM y Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[['RISK_MM', 'Rainfall']] = df_original[['RISK_MM', 'Rainfall']].astype('float')\n",
    "\n",
    "# Histogramas, boxplot y cálculo de skewness/kurtosis de RISK_MM y Rainfall\n",
    "sns.histplot(df_original['RISK_MM'], kde=True, bins=30)\n",
    "plt.title('Distribución de RISK_MM')\n",
    "plt.xlabel('RISK_MM')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df_original['RISK_MM'])\n",
    "plt.title('Boxplot de RISK_MM')\n",
    "plt.xlabel('RISK_MM')\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness de RISK_MM:\", df_original['RISK_MM'].skew())\n",
    "print(\"Kurtosis de RISK_MM:\", df_original['RISK_MM'].kurt())\n",
    "\n",
    "sns.histplot(df_original['Rainfall'], kde=True, bins=30)\n",
    "plt.title('Distribución de Rainfall')\n",
    "plt.xlabel('Rainfall')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=df_original['Rainfall'])\n",
    "plt.title('Boxplot de Rainfall')\n",
    "plt.xlabel('Rainfall')\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness de Rainfall:\", df_original['Rainfall'].skew())\n",
    "print(\"Kurtosis de Rainfall:\", df_original['Rainfall'].kurt())\n",
    "\n",
    "# Las variables RISK_MM y Rainfall tienen una distribución sesgada a la izquierda, por lo que aplicamos una transformación logarítmica para normalizar su distribución.\n",
    "df_original['RISK_MM'] = np.log1p(df_original['RISK_MM'])\n",
    "df_original['Rainfall'] = np.log1p(df_original['Rainfall'])\n",
    "# Graficamos la distribución de las variables transformadas \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_original['RISK_MM'], kde=True, bins=30)\n",
    "plt.title('Distribución de RISK_MM (Transformada)')\n",
    "plt.xlabel('RISK_MM (Transformada)')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_original['Rainfall'], kde=True, bins=30)\n",
    "plt.title('Distribución de Rainfall (Transformada)')\n",
    "plt.xlabel('Rainfall (Transformada)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66120c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación si faltan registros, se rellenan con la mediana global o de grupo\n",
    "df_original['Rainfall'] = df_original.groupby(['Location', 'Month'], observed=False)['Rainfall'].transform(lambda x: x.fillna(x.median() if not pd.isna(x.median()) else 0))\n",
    "df_original['RISK_MM'] = df_original.groupby(['Location', 'Month'], observed=False)['RISK_MM'].transform(lambda x: x.fillna(x.median() if not pd.isna(x.median()) else 0))\n",
    "\n",
    "# Revisamos si quedan valores nulos\n",
    "missing_values = df_original.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nValores nulos por columna después de la imputación:\\n\")\n",
    "print(missing_values[missing_values > 0]) # Solo muestra columnas con nulos\n",
    "present_values = df_original.notna().sum().sort_values(ascending=False)\n",
    "print(\"\\nValores presentes por columna:\\n\")\n",
    "print(present_values[present_values > 0]) # Solo muestra columnas sin nulos\n",
    "# Verificamos nuevamente la información del dataset después de las conversiones\n",
    "df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a992de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_encoded = df_original.copy()\n",
    "\n",
    "# Codificamos las direcciones del viento\n",
    "wind_directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
    "wind_mapping = {direction: i for i, direction in enumerate(wind_directions)}\n",
    "df_original_encoded['WindGustDir'] = df_original_encoded['WindGustDir'].map(wind_mapping).astype('category')\n",
    "df_original_encoded['WindDir9am'] = df_original_encoded['WindDir9am'].map(wind_mapping).astype('category')\n",
    "df_original_encoded['WindDir3pm'] = df_original_encoded['WindDir3pm'].map(wind_mapping).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29061112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación binaria para RainToday y RainTomorrow\n",
    "df_original_encoded['RainToday'] = df_original_encoded['RainToday'].map({'No': 0, 'Yes': 1}).astype('category')\n",
    "df_original_encoded['RainTomorrow'] = df_original_encoded['RainTomorrow'].map({'No': 0, 'Yes': 1}).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandardizamos las variables numéricas\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df_original_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_original_encoded[numeric_cols] = scaler.fit_transform(df_original_encoded[numeric_cols])\n",
    "\n",
    "df_original_encoded "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3ec87",
   "metadata": {},
   "source": [
    "Ingeniería de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rangos y promedios de las variables numéricas\n",
    "df_original_encoded['TempRange'] = df_original_encoded['MaxTemp'] - df_original_encoded['MinTemp']\n",
    "df_original_encoded['WindSpeedAvg'] = (df_original_encoded['WindSpeed9am'] + df_original_encoded['WindSpeed3pm']) / 2\n",
    "\n",
    "# Interacciones\n",
    "df_original_encoded['RainTempInteraction'] = df_original_encoded['Rainfall'] * df_original_encoded['TempRange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f745a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lags y medias móviles\n",
    "df_original_encoded['Rainfall_Lag1'] = df_original_encoded.groupby('Location')['Rainfall'].shift(1) # Lluvia del día anterior\n",
    "df_original_encoded['Rainfall_ma3'] = df_original_encoded.groupby('Location')['Rainfall'].rolling(3).mean().reset_index(0, drop=True) # Media móvil de 3 días"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c7a4d",
   "metadata": {},
   "source": [
    "Selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c460b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de correlación de variables solamente numéricas vs. RISK_MM y RainTomorrow\n",
    "correlation_matrix = df_original_encoded.select_dtypes(include=['float64', 'int64']).corr()\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Mapa de Calor de Correlaciones entre Variables Numéricas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de características en base al gráfico anterior con un modelo de Random Forest\n",
    "# Entrenamos un modelo de Random Forest para evaluar la importancia de las características\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "X = df_original_encoded.drop(columns=['Location', 'Date', 'RainTomorrow', 'RISK_MM', 'Season'])\n",
    "rfr.fit(X, df_original_encoded['RISK_MM'])\n",
    "importances = pd.Series(rfr.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "top_features = importances.head(20).index.tolist()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[top_features], y=top_features, palette='viridis')\n",
    "plt.title('Importancia de Características (Top 20)')\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087feed",
   "metadata": {},
   "source": [
    "### Selección de las 10 variables más importantes para predecir RISK_MM\n",
    "\n",
    "A continuación, se seleccionan las 10 variables más relevantes según la importancia obtenida con un modelo de Random Forest. Estas variables serán utilizadas como predictores en el modelo de regresión para RISK_MM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db509a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos un Random Forest para obtener la importancia de las variables\n",
    "\n",
    "X_full = df_original_encoded.drop(columns=['Location', 'Date', 'RainTomorrow', 'RISK_MM', 'Season'])\n",
    "y_full = df_original_encoded['RISK_MM']\n",
    "\n",
    "\n",
    "rfr.fit(X_full, y_full)\n",
    "\n",
    "importances = pd.Series(rfr.feature_importances_, index=X_full.columns)\n",
    "top10_features = importances.sort_values(ascending=False).head(10).index.tolist()\n",
    "print(\"Top 10 variables más importantes para predecir RISK_MM:\")\n",
    "print(top10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4611616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los conjuntos de datos solo con las 10 variables seleccionadas\n",
    "X = df_original_encoded[top10_features]\n",
    "y = df_original_encoded['RISK_MM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fcfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d4b93",
   "metadata": {},
   "source": [
    "# Fase 4 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a99368",
   "metadata": {},
   "source": [
    "### Modelado de regresión con los 10 mejores predictores\n",
    "\n",
    "Se entrenarán y evaluarán los siguientes modelos de regresión:\n",
    "- Regresión Lineal\n",
    "- Random Forest Regressor\n",
    "- K-Nearest Neighbors Regressor\n",
    "- Naive Bayes (GaussianNB adaptado para regresión)\n",
    "\n",
    "Se utilizarán métricas como R2 Score, MAE, RMSE y, para propósitos ilustrativos, una matriz de confusión discretizando los valores predichos y reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2399a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos a comparar\n",
    "models = {\n",
    "    'Regresión Lineal': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Naive Bayes':\n",
    "        # GaussianNB es para clasificación, se adapta para regresión discretizando y luego prediciendo la media de cada clase\n",
    "        # Discretizamos y_train en 10 bins\n",
    "        y_train_disc = np.digitize(y_train, np.histogram(y_train, bins=10)[1][1:-1])\n",
    "        model.fit(X_train, y_train_disc)\n",
    "        y_pred_disc = model.predict(X_test)\n",
    "        # Para comparar con regresión, convertimos los bins a valores medios\n",
    "        bin_edges = np.histogram(y_train, bins=10)[1]\n",
    "        y_pred = np.array([(bin_edges[int(i)]+bin_edges[int(i)+1])/2 if 0 <= int(i) < len(bin_edges)-1 else y_train.mean() for i in y_pred_disc])\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'y_pred': y_pred}\n",
    "    print(f\"\\nModelo: {name}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R2: {r2:.4f}\")\n",
    "\n",
    "# Visualización de predicciones vs. valores reales\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, (name, res) in enumerate(results.items(), 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(y_test, res['y_pred'], alpha=0.3, s=10)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Valor Real (RISK_MM)')\n",
    "    plt.ylabel('Predicción')\n",
    "    plt.title(f'{name}\\nR2: {res[\"R2\"]:.2f}, RMSE: {res[\"RMSE\"]:.2f}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc91bf6",
   "metadata": {},
   "source": [
    "### Matriz de confusión (valores discretizados)\n",
    "\n",
    "Para ilustrar la calidad de las predicciones, se discretizan los valores reales y predichos en 5 categorías y se muestra la matriz de confusión para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 5\n",
    "kbin = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "y_test_binned = kbin.fit_transform(y_test.values.reshape(-1, 1)).astype(int).flatten()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, (name, res) in enumerate(results.items(), 1):\n",
    "    y_pred_binned = kbin.transform(res['y_pred'].reshape(-1, 1)).astype(int).flatten()\n",
    "    cm = confusion_matrix(y_test_binned, y_pred_binned)\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de confusión - {name}')\n",
    "    plt.xlabel('Predicción (binned)')\n",
    "    plt.ylabel('Real (binned)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45a6c9",
   "metadata": {},
   "source": [
    "**Conclusiones:**\n",
    "\n",
    "- Se compararon cuatro modelos de regresión, incluyendo una adaptación de Naive Bayes.\n",
    "- Se evaluaron con métricas de regresión y matriz de confusión discretizada.\n",
    "- El modelo con mejor R2 y menor RMSE/MAE es el más recomendable para la predicción de RISK_MM.\n",
    "- La matriz de confusión ayuda a visualizar la capacidad de los modelos para predecir rangos de la variable objetivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
